### Архитектура Panoptic FPN

- Основа сети — **FPN**, популярный для задач обнаружения объектов.
- К нему добавляется ветвь для семантической сегментации, работающая параллельно с существующей ветвью для инстанс-сегментации.
- Ветвь для семантической сегментации **легкая**, не требует изменений в FPN и полностью совместима с существующими методами инстанс-сегментации.
![[Pasted image 20251117014358.png]]
Иллюстрация :
1. FPN backbone — извлечение многоуровневых признаков.
2. Ветвь инстанс-сегментации — как в Mask R-CNN.
3. Ветвь семантической сегментации — плотные предсказания для каждого пикселя.
#### Feature Pyramid Network (FPN)
- FPN использует стандартную сверточную сеть (например, **ResNet**) с признаками на разных масштабах.
- Затем добавляет **верхнюю нисходящую пирамиду**: начиная с максимального уровня (самого глубокого слоя), постепенно увеличивает разрешение, добавляя признаки из нижних уровней.
- Такой подход создает **многоуровневую пирамиду признаков** с масштабами от **1/32 до 1/4** от исходного разрешения.
- Каждый уровень пирамиды содержит **одинаковое количество каналов** (по умолчанию 256).
#### Ветка для инстанс-сегментации
- Благодаря одинаковому размеру каналов на каждом уровне, к FPN легко присоединяется заданный регионный детектор, например Faster R-CNN 
- В Mask R-CNN это дополнено предсказанием **масок сегментации объектов** для каждого региона.
- Семантическая ветка 
- Для каждого уровня FPN (1/32, 1/16, 1/8, 1/4) выполняется **последовательное увеличение разрешения** до общей 1/4 шкалы.
- Каждый этап содержит:
    - Свёртку 3×3
    - **GroupNorm**  и **ReLU**
    - **Билинейное увеличение** ×2
- Все полученные признаки (на масштабе 1/4) **складываются поэлементно**.
- Затем применяется:
    - **1×1 свёртка**
    - Билинейное увеличение ×4
    - **Softmax**
![[Pasted image 20251117015524.png]]
Результат — плотная (пиксельная) карта классов в исходном разрешении изображения.

---

**Обучение**
Сеть обучается сразу на две цели, поэтому и функция потерь состоит из двух компонентов:
Проблема: разные масштабы потерь
- Потери инстанс-ветки и семантики имеют **разный порядок величины**
- Если просто сложить их:
    - Одна из задач может начать доминировать
    - Производительность другой снизится — модель будет "жертвовать" ей
Решение: взвешивание потерь
## Функция потерь Panoptic FPN

Итоговая функция потерь:

L = λᵢ · (L_c + L_b + L_m) + λₛ · Lₛ
 - L_c — loss для классификации объектов (кросс-энтропия)
- L_b — loss для регрессии bounding box (smooth L1 или L2)
- L_m — loss для предсказания масок объектов (binary cross-entropy)
- Lₛ — loss для семантической сегментации (pixel-wise cross-entropy)
- λᵢ — весовой коэффициент для instance-потерь
- λₛ — весовой коэффициент для semantic-потерь
Обычно:
- λᵢ ≈ 1.0
- λₛ ≈ 0.5 или 1.0 (зависит от относительной важности задачи)
Эта формула объединяет ошибки двух задач в одну величину, которую и оптимизирует градиентный спуск.
![[Pasted image 20251117021346.png]]По результатам риснка
- FPN ≈ dilated network с шагом 16, но делает выход в 4 раза выше по разрешению.
- При этом:
    - **≈2 раза эффективнее**, чем U-Net (симметричный декодер)
    - Гораздо легче, чем dilated networks с высоким разрешением
- (a) **Обычная сеть**
- (b) **Дилатированные свёртки**
- (c) **Симметричный декодер** (U-Net)
- (d) **FPN**: лёгкий асимметричный декодер с общей размерностью каналов
Итог: **FPN — эффективная и совместимая с Mask R-CNN альтернатива** для задач паноптической сегментации

---
# Panoptic FPN — Эксперименты и результаты

## Цели экспериментов
- Проверить, может ли **одна сеть** эффективно решать **инстанс-сегментацию, семантическую сегментацию и паноптическую сегментацию**.
- Проверить, можно ли **объединить обучение двух задач** без потери точности.
- Сравнить **одну сеть против двух отдельных сетей** (по точности и ресурсам).
- Проверить, как **разные архитектурные решения и параметры** влияют на точность и эффективность.

---
##  Что проверяли

### A. Semantic Segmentation (Semantic FPN)

- Насколько простая ветка для семантики на FPN конкурентоспособна с современными методами (DeepLab, PSPNet, etc.).
- Влияние:
    - Количества каналов (64, 128, 256) → точность/эффективность
    - Способа агрегации FPN-уровней (суммирование vs конкатенация)
- Метрики: **mIoU, fIoU, iIoU**
### B. Multi-Task Training
- Можно ли совместно обучать семантику и инстансы без ухудшения каждой задачи.
- Проверка **веса потерь** λₛ (семантика) и λᵢ (инстансы):
    - Разные комбинации λ → смещение влияния одной задачи на другую
    - Проверка, есть ли синергия между задачами
- Метрики: **AP, mIoU, PQ, PQTh, PQSt**
### C. Panoptic Segmentation

- Проверка производительности **одной модели Panoptic FPN** против:
    
    - Двух отдельных FPN для инстансов и семантики
    - Разных бэкбонов (ResNet-50 vs ResNet-101)
- Стратегии обучения:
    
    - Совмещение потерь в одном мини-батче
    - Чередование задач
- Проверка группировки каналов FPN под отдельные ветки
- Метрики: **PQ, PQTh, PQSt**
    

### D. Сравнение с SOTA

- Проверка, насколько Panoptic FPN конкурентоспособна с:
    - Одно-модельными участниками COCO Panoptic Segmentation Challenge
    - Современными подходами для Cityscapes (например, DIN)
- Цель: установить новый **baseline** для паноптической сегментации.

---

##  Что получилось

### A. Semantic FPN

- Простая семантическая ветка на FPN показала **конкурентные результаты** с DeepLab и PSPNet.
- Оптимально 128 каналов в ветке семантики.
- Суммирование FPN-уровней лучше, чем конкатенация.
- Эффективнее по ресурсам (FLOPs и память) чем dilated-сети.

### B. Multi-Task Training

- Добавление семантической ветки может **улучшить инстанс-сегментацию**, и наоборот.
- Корректная настройка λᵢ и λₛ позволяет одной модели быть **сравнимой с двумя отдельными**.
- Совместная функция потерь лучше, чем чередование задач.

### C. Panoptic Segmentation

- **Одна Panoptic FPN** ≈ две отдельные FPN по точности, но **вдвое меньше вычислений**.
- Более сильный бэкбон (R101-FPN) → превосходит две слабые сети при равных ресурсах.
- Группировка каналов FPN даёт смешанные результаты, нужна доработка.

### D. Сравнение с SOTA

- **COCO**: PQ = 40.9, выше всех одно-модельных участников на ~9 пунктов.
- **Cityscapes**: PQ = 58.1, выше DIN на 4.3 пункта.
- Без сложных трюков, без ансамблей — чистый, быстрый и точный baseline.

---

##  Выводы

- Panoptic FPN — простая, но **эффективная сеть** для трех задач.
- Объединённое обучение улучшает обе задачи и экономит ресурсы.
- Подходит как **baseline** для дальнейших исследований в паноптической сегментации.
- Архитектура легко масштабируется (разные бэкбоны, увеличение канало

---