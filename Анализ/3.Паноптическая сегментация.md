**Сегментация** в компьютерном зрении - это задача разделения изображения на осмысленные части.
**Семантическая сегментация** - это когда каждый пиксель изображения получает метку, которая обозначает, к какому классу он относится.
**Сегментация экземпляров** - она различает каждый отдельный объект и делить его по классам.
**Паноптическая сегментация** - объединяет выше перечисленные виды сегментации, таким образом каждый пиксель получает свою метку и класс и при возможности номер объекта.
**Как устроен формат данных для паноптической сегментации**
Сначала авторы вводят базовое представление: у нас есть набор семантических классов — например, «небо», «дорога», «машина», «человек». Для каждого пикселя изображения паноптическая сегментация должна выдать пару значений: семантический класс и id экземпляра. Семантический класс говорит, что изображено в этом пикселе, а идентификатор экземпляра показывает, к какому конкретному объекту этот пиксель относится (например, к первому или второму человеку). У пикселей, которые относятся к одному и тому же объекту, должны быть одинаковые пара (класс, id). Если какой-то пиксель нельзя отнести ни к одному классу (например, артефакт), ему можно назначить специальную метку - void.
**Различие между stuff** и **things**. 
	Stuff - это фоновые, «неразделяемые на объекты» классы, такие как небо, трава или дорога. 
	Thing - это объекты, которые имеют отдельные экземпляры: люди, машины, животные. 
	Если пиксель относится к классу stuff, его instance-id не имеет смысла, потому что у фона нет отдельных объектов - всё небо считается «одним небом». Если пиксель относится к things, то разные объекты одного класса должны иметь разные id.
Как паноптическая сегментация связана с обычной семантической сегментацией. Паноптический формат полностью включает семантический. Если бы в изображении были только stuff-классы, или если бы мы игнорировали instance-id, то формат был бы таким же, как у обычной семантической сегментации. Разница появляется только тогда, когда появляются thing-классы, которые могут иметь несколько экземпляров. В instance-сегментации разные объекты могут перекрывать друг друга — например, маска одной машины может частично накрывать маску другой, если они перекрываются по глубине. В паноптической сегментации это невозможно, потому что каждый пиксель может иметь только одну пару (класс, id), то есть принадлежать одному объекту.
**Метрика** — это способ измерить, насколько хорошо работает модель
 **PQ (Panoptic Quality)**, :
	Объединяет в себе оценку и объектов (things), и фона (stuff).
	Позволяет одним числом измерить качество всей сцены целиком, а не отдельных задач.
	Формула PQ учитывает:
		 - Насколько хорошо модель распознала объекты (границы, классы).
		 - Насколько точно она разметила фоновые области, такие как небо, дорога, трава.
Три основных требования (desiderata), которые должны быть соблюдены при создании такой метрики:
	**Полнота (Completeness):** метрика должна одинаково измерять качество сегментации и для stuff, и для things — то есть должна охватывать все типы классов.
	**Интерпретируемость (Interpretability):** результат должен иметь понятный смысл — например, в процентах или баллах, чтобы сразу было ясно, что значит, если PQ = 0.8.
	**Простота (Simplicity):** метрика должна быть легко определима и вычислима — чтобы её могли использовать разные исследователи, сравнивать результаты между работами и повторять опыты.
Оценка PQ состоит из двух этапов:
	**Сопоставление сегментов** (segment matching): сначала нужно понять, какие предсказанные сегменты соответствуют истинным сегментам (например, человек на предсказанной маске соответствует человеку на ground truth).
    **Вычисление PQ** исходя из этих сопоставлений: здесь учитывают и качество совпадения масок (например, через IoU), и количество правильно найденных или пропущенных объектов.
**Как вычисляет IOU**
$$
IoU = \frac{|p \cap g|}{|p \cup g|}
$$
$$|p \cup g|$$ количество пикселей, которые совпадают в обоих сегментах
$$|p \cup g|$$ общее количество пикселей, которые есть хотя бы в одном из сегментов
### Пример

Представь, что сегмент человека на изображении занимает **10 пикселей**, а модель выделила **8 пикселей**.

- Из этих 8 пикселей **6 попадают точно в настоящий объект** (пересечение).
    
- Объединение — это все пиксели, которые есть хотя бы в одном из сегментов, то есть 10+8−6=1210 + 8 - 6 = 1210+8−6=12 пикселей.
- IoU = пересечение / объединение = 6/12 = 0.5
 
Если IoU > 0.5, сегменты считаются совпавшими для метрики PQ.
**Вычисление PQ (Panoptic Quality)**
После того, как мы **сопоставили сегменты** (matched segments по IoU > 0.5), у нас есть три группы сегментов для каждого класса:

1. **TP (True Positives)** — сегменты, которые совпали с ground truth.
2. **FP (False Positives)** — предсказанные сегменты, которым не нашлось соответствия.
3. **FN (False Negatives)** — сегменты из ground truth, которые модель пропустила.
$$
PQ = \frac{\sum_{(p,g) \in TP} IoU(p, g)}{|TP| + \frac{1}{2}|FP| + \frac{1}{2}|FN|}
$$
- Числитель:  суммируем IoU для всех правильно совпавших сегментов. Это **качество сегментации** (насколько точно модель очертила объекты).
- Знаменатель: добавляем половину «штрафа» за пропущенные объекты и ложные предсказания. Так PQ учитывает и **качество распознавания объектов**, а не только точность формы сегмента.
**Разделение на SQ и RQ**
$$
PQ = SQ \times RQ
$$
**Сегментационное качество (SQ):**

$$
SQ = \frac{\sum_{(p,g) \in TP} IoU(p, g)}{|TP|}
$$
Просто среднее IoU для правильно совпавших сегментов.
**Качество распознавания (RQ):**

$$
RQ = \frac{|TP|}{|TP| + \frac{1}{2}|FP| + \frac{1}{2}|FN|}
$$
Это похоже на F1-меру, показывает, насколько хорошо модель нашла все объекты и не сделала лишних предсказаний.

### **Человек vs. Машина**

**Выводы:**

1. **SQ (качество сегментации)** — машины почти такие же, как люди, особенно для больших объектов.
2. **RQ (качество распознавания)** — машины сильно уступают людям. То есть основная проблема машин — **правильно распознавать объекты**.
3. Общий **PQ** машин ниже, чем у людей — особенно на сложном датасете **ADE20k**.![[1801.00868v3 (2).pdf]]![[1801.00868v3.pdf]]