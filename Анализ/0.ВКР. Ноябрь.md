 

  

Общий план выглядит следующим образом. В принципе, эти же этапы и пойдут в саму вкр в виде основных глав.

  

1. Аналитический обзор

2. Разработка модели

3. Численные эксперименты

  
  

Сейчас нужно разобрать некоторые компоненты, которые понадобятся при дальнейшем проектировании и датасеты. От выбранного набора будет скорректирована общая цель и подзадачи.

  

Также получить общее представление о том с чем придется работать. Будем все делать поэтапно, поэтому первая пачка материалов для изучения.

## **По задаче и компонентам:**

  

1. По формату самих данных с которым придется работать. [https://deepschool-pro.notion.site/a719a12a42ca4ca18eef24b161d027ac](https://deepschool-pro.notion.site/a719a12a42ca4ca18eef24b161d027ac)

  

2. Что из себя представляет паноптическая сегментация и как формализована эта задача (здесь речь про изображения, тем не менее все это дело можно переложить на облака точек):

   [https://arxiv.org/pdf/1801.00868v3.pdf](https://arxiv.org/pdf/1801.00868v3.pdf)

  

3. Дилатационная свертка (здесь про ее обобщение над графами):

     [https://arxiv.org/pdf/1907.09798.pdf](https://arxiv.org/pdf/1907.09798.pdf)

4. Немного основ про имплементацию паноптической пирамиды: [https://arxiv.org/pdf/1901.02446v2.pdf](https://arxiv.org/pdf/1901.02446v2.pdf)

  

## **По моделям:**

  

- прочитать обзор [https://habr.com/en/companies/itmai/articles/549716/](https://habr.com/en/companies/itmai/articles/549716/) (+можно посмотреть на paperswithcode по поиску panoptic/instance point cloud segmentation)

- В качестве начального погружения в модельный ряд и область будем смотреть в хронологическом порядке поэтому сначала надо ознакомиться с вот этим: [https://paperswithcode.com/method/gcn](https://paperswithcode.com/method/gcn) здесь и описание операции свертки над графами и их применение.

  

- в качестве первой модели для изучения: [https://medium.com/@luis_gonzales/an-in-depth-look-at-pointnet-111d7efdaa1a](https://medium.com/@luis_gonzales/an-in-depth-look-at-pointnet-111d7efdaa1a) Рекомендую потом посмотреть оригинальную статью, она достаточно старая, но как отправная точка очень даже подойдет. Если трудностей не вызовет, то сразу зацепить Pointnet++.

  

- Далее рассмотреть несколько моделей, (причем одна есть развитие другой), здесь важно разобраться с механизмом представления графов. + Найти/запустить реализации на торче, в общем, проверить работоспособность.

  

1. [DGCNN](https://arxiv.org/pdf/1801.07829.pdf) -  здесь нас интересует ветка отвечающая за сегментацию

2. [LDGCNN](https://arxiv.org/pdf/1904.10014v2.pdf)

  

## По наборам:

  

Пройтись по датасетам и выбрать. Относительно задачи с дорожными сценариями их много, предлагаю рассмотреть те что в списке. Обратить внимание на объем самих данных.

  

**Дорожные**

  

1. [NuScenes](https://www.nuscenes.org/nuscenes)

2. [KITTI (на задаче 3D Instance Segmentation)](https://www.cvlibs.net/datasets/kitti-360/leaderboard_scene_understanding.php?task=ins3d)

3. [NCLT Vision and Lidar Dataset](https://robots.engin.umich.edu/)

4. [OXFORD Robotcar Dataset](https://robotcar-dataset.robots.ox.ac.uk/)

5. [Woven Planet Perception Dataset](https://www.woven-planet.global/en/data/perception-dataset)

6. [SYDNEY URBAN OBJECTS DATASET](https://www.acfr.usyd.edu.au/papers/SydneyUrbanObjectsDataset.shtml)

7. [H3D Honda 3D Dataset](https://usa.honda-ri.com/H3D)

8. [Waymo](https://waymo.com/open/)

9. [Paris-Lille-3D](https://npm3d.fr/paris-lille-3d)[Audi Autonomous Driving Dataset (A2D2)](https://www.a2d2.audi/a2d2/en/dataset.html)

  

Синтетика, тоже интересно:

  

1. [SynthCity](http://www.synthcity.xyz/)

2. [SynLiDAR](https://github.com/xiaoaoran/SynLiDAR)

  
  

По минимальным требованиям основное - это составить вменяемый аналитический обзор по существующим подходам, наборам и метрикам, сформировать требования к разрабатываемой модели и подготовиться к серии численных экспериментов.

  

Для самого отчета срок - конец декабря.

  

По рассматриваемым моделям и тестам будут еще, но вот с представленными материалами необходимо разобраться максимально подробно.

  

Разработка самой модели будет следующим этапом.

  
  

## **По стеку**

- торч

-  как говорил на встрече необходимо разобраться с трекерами экспериментов типа ClearML. Альтернативно, Weights and Biases, или Aim.

  

## **По отчетности**

  

- Отчетность - еженежельная, выбираете день, появляетесь, осуждаем что сделано

 итд.

 - Необходимо завести страницу где нибудь в notion, но возможно там бан. Поэтому, нужно найти сервис где можно будет смотреть прогресс и выкладывать промежуточные результаты. Как вариант тот же wandb reports. Либо просто общий документ на драйве, с расшаренным доступом.